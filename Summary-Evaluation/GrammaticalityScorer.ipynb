{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 15000000\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import readability\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./summary_quality/train_data.json\",'r') as fin:\n",
    "    train_content = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./summary_quality/test_data.json\",'r') as fin:\n",
    "    test_content = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature1(wordList):\n",
    "    count = 0\n",
    "    i = 0\n",
    "    while i < len(wordList) - 1:\n",
    "        j = i+1\n",
    "        if wordList[i] == wordList[j]:\n",
    "            count += 1\n",
    "            while j < len(wordList)-1 and wordList[i] == wordList[j]:\n",
    "                j+=1\n",
    "        i = j\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature2(wordList):\n",
    "    count = 0\n",
    "    i = 0\n",
    "    while i < len(wordList) - 3:\n",
    "        j = i+2\n",
    "        if wordList[i+1] != wordList[i] and wordList[i] == wordList[j] and wordList[i+1] == wordList[j+1]:\n",
    "            count += 1\n",
    "            while j < len(wordList)-2 and  wordList[i+1] != wordList[i] and wordList[i] == wordList[j] and wordList[i+1] == wordList[j+1]:\n",
    "                j+=2\n",
    "            i = j      \n",
    "        else:\n",
    "            i += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature3(doc):\n",
    "    fletcherScores = []\n",
    "    for sent in doc.sents:\n",
    "        try:\n",
    "            scores = readability.getmeasures(sent.text, lang='en')\n",
    "            fletcherScores.append(scores['readability grades']['FleschReadingEase'])\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return min(fletcherScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature4(doc):\n",
    "    sva_count = 0\n",
    "    for i,sent in enumerate(doc.sents):\n",
    "        text_ext = textacy.extract.subject_verb_object_triples(sent)\n",
    "        count = 0\n",
    "        for t in text_ext:\n",
    "            count += 1\n",
    "        sva_count += 1 if count > 0 else 0\n",
    "    return sva_count/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature5(doc):\n",
    "    scores = readability.getmeasures(doc.text, lang='en')\n",
    "    return scores['sentence info']['words_per_sentence']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run cell for three features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docFeature = OrderedDict()\n",
    "for file in os.listdir(\"./summary_quality/summaries/\"):\n",
    "    f = open(\"./summary_quality/summaries/\"+file, encoding = \"ISO-8859-1\")\n",
    "    text = f.read()\n",
    "    doc = nlp(text)\n",
    "    wordList=[]\n",
    "    for token in doc:\n",
    "        lexeme = nlp.vocab[token.text]\n",
    "        if lexeme.is_stop == False and token.pos_ != \"PUNCT\" and token.pos_ != \"SPACE\" and token.pos_ != \"SYM\":\n",
    "            wordList.append(token.text.lower())\n",
    "    t = (getFeature1(wordList),getFeature2(wordList),getFeature3(doc))\n",
    "    docFeature[file] = t\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test data\n",
    "feature_X_Y = OrderedDict()\n",
    "for k,v in sorted(train_content.items(), key=lambda x: x):\n",
    "    feature_X_Y[k] = (docFeature[k],v['grammaticality'])\n",
    "test_X_Y = OrderedDict()\n",
    "for k,v in sorted(test_content.items(), key=lambda x: x):\n",
    "    test_X_Y[k] = (docFeature[k],v['grammaticality'])\n",
    "test_x = []\n",
    "test_y = []\n",
    "for k,v in test_X_Y.items():\n",
    "    test_x.append([float(v[0][0]),float(v[0][1]),float(v[0][2])])\n",
    "    test_y.append(float(v[1]))\n",
    "    train_x = []\n",
    "train_y = []\n",
    "for k,v in feature_X_Y.items():\n",
    "    train_x.append([float(v[0][0]),float(v[0][1]),float(v[0][2])])\n",
    "    train_y.append(float(v[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Cell for 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docFeature = OrderedDict()\n",
    "for file in os.listdir(\"./summary_quality/summaries/\"):\n",
    "    f = open(\"./summary_quality/summaries/\"+file, encoding = \"ISO-8859-1\")\n",
    "    text = f.read()\n",
    "    doc = nlp(text)\n",
    "    wordList=[]\n",
    "    for token in doc:\n",
    "        lexeme = nlp.vocab[token.text]\n",
    "        if lexeme.is_stop == False and token.pos_ != \"PUNCT\" and token.pos_ != \"SPACE\" and token.pos_ != \"SYM\":\n",
    "            wordList.append(token.text.lower())\n",
    "    t = (getFeature1(wordList),getFeature2(wordList),getFeature3(doc),getFeature4(doc),getFeature5(doc))\n",
    "    docFeature[file] = t\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test data\n",
    "feature_X_Y = OrderedDict()\n",
    "for k,v in sorted(train_content.items(), key=lambda x: x):\n",
    "    feature_X_Y[k] = (docFeature[k],v['grammaticality'])\n",
    "test_X_Y = OrderedDict()\n",
    "for k,v in sorted(test_content.items(), key=lambda x: x):\n",
    "    test_X_Y[k] = (docFeature[k],v['grammaticality'])\n",
    "test_x = []\n",
    "test_y = []\n",
    "for k,v in test_X_Y.items():\n",
    "    test_x.append([float(v[0][0]),float(v[0][1]),float(v[0][2]),float(v[0][3]),float(v[0][4])])\n",
    "    test_y.append(float(v[1]))\n",
    "    train_x = []\n",
    "train_y = []\n",
    "for k,v in feature_X_Y.items():\n",
    "    train_x.append([float(v[0][0]),float(v[0][1]),float(v[0][2]),float(v[0][3]),float(v[0][4])])\n",
    "    train_y.append(float(v[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run cell below to fit and show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6727410798116299\n",
      "(0.02749712721445367, 0.7042478697495957)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(train_x,train_y)\n",
    "y_pred = regressor.predict(test_x)\n",
    "print(mean_squared_error(test_y,y_pred))\n",
    "print(pearsonr(test_y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
