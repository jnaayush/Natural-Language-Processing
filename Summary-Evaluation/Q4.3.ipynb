{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x136e921d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import readability\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import textacy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import gensim\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import neuralcoref\n",
    "nlp = spacy.load(\"en\")\n",
    "nlp.max_length = 15000000\n",
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./summary_quality/train_data.json\",'r') as fin:\n",
    "    train_content = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./summary_quality/test_data.json\",'r') as fin:\n",
    "    test_content = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature1(doc):\n",
    "    nounChunks = {}\n",
    "    for chunk in doc.noun_chunks:\n",
    "        c = nounChunks.get(chunk,0)\n",
    "        nounChunks[chunk] = c+1\n",
    "        if c+1 > 1:\n",
    "            print(nounChunks)\n",
    "    return len([val for val in nounChunks.values() if val > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeature2(doc):\n",
    "    if doc._.has_coref:\n",
    "        return len(doc._.coref_clusters)\n",
    "    else :\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "docFeature = OrderedDict()\n",
    "for file in os.listdir(\"./summary_quality/summaries/\"):\n",
    "#     print(file)\n",
    "    f = open(\"./summary_quality/summaries/\"+file, encoding = \"ISO-8859-1\")\n",
    "    text = f.read().lower()\n",
    "    doc = nlp(text)\n",
    "    wordList=[]\n",
    "    for token in doc:\n",
    "        if token.pos_ != \"PUNCT\" and token.pos_ != \"SPACE\" and token.pos_ != \"SYM\":\n",
    "            wordList.append(token.text.lower())\n",
    "    doc = nlp(\" \".join(wordList))\n",
    "    t = (getFeature1(doc),getFeature2(doc))\n",
    "    docFeature[file] = t\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test data\n",
    "feature_X_Y = OrderedDict()\n",
    "for k,v in sorted(train_content.items(), key=lambda x: x):\n",
    "    feature_X_Y[k] = (docFeature[k],v['coherence'])\n",
    "test_X_Y = OrderedDict()\n",
    "for k,v in sorted(test_content.items(), key=lambda x: x):\n",
    "    test_X_Y[k] = (docFeature[k],v['coherence'])\n",
    "test_x = []\n",
    "test_y = []\n",
    "for k,v in test_X_Y.items():\n",
    "    test_x.append([float(v[0][0]),float(v[0][1])])\n",
    "    test_y.append(float(v[1]))\n",
    "    train_x = []\n",
    "train_y = []\n",
    "for k,v in feature_X_Y.items():\n",
    "    train_x.append([float(v[0][0]),float(v[0][1])])\n",
    "    train_y.append(float(v[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE  1.0543990943762727\n",
      "SVR Pearson  (-0.08277872745551723, 0.2524189297053374)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "regressor = SVR(kernel='rbf')\n",
    "regressor.fit(train_x,train_y)\n",
    "y_pred = regressor.predict(test_x)\n",
    "print(\"SVR MSE \",mean_squared_error(test_y,y_pred))\n",
    "print(\"SVR Pearson \",pearsonr(test_y,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
