{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "inPath = \"./train\"\n",
    "testPath = \"./test\"\n",
    "fileExtension = \".txt\"\n",
    "outPathText = \"./Processed_text\"\n",
    "outPathJson = \"./Output\"\n",
    "word_count = {}\n",
    "unigram_count = {}\n",
    "bigram_count = {}\n",
    "trigram_count = {}\n",
    "lambdas = []\n",
    "minLambda = []\n",
    "lambdas.append([0.4,0.3,0.3])\n",
    "lambdas.append([0.3,0.4,0.3])\n",
    "lambdas.append([0.1,0.7,0.2])\n",
    "lambdas.append([0.5,0.4,0.3])\n",
    "lambdas.append([0.1,0.4,0.5])\n",
    "lambdas.append([0.7,0.2,0.1])\n",
    "lambdas.append([0.8,0.1,0.1])\n",
    "lambdas.append([0.1,0.8,0.1])\n",
    "lambdas.append([0.1,0.2,0.8])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dicts():\n",
    "    word_count = {}\n",
    "    unigram_count = {}\n",
    "    bigram_count = {}\n",
    "    trigram_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUnigrams(wordList,outDict):\n",
    "    for i in range(0, len(wordList)):\n",
    "        unigram = wordList[i]\n",
    "        if unigram in outDict:\n",
    "            outDict[unigram] = outDict[unigram] + 1\n",
    "        else:\n",
    "            outDict[unigram] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBigrams(wordList,outDict):\n",
    "    for i in range(0, len(wordList) - 1, 2):\n",
    "        bigram = wordList[i] + \" \" + wordList[i + 1]\n",
    "        if bigram in outDict:\n",
    "            outDict[bigram] = outDict[bigram] + 1\n",
    "        else:\n",
    "            outDict[bigram] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrigrams(wordList,outDict):\n",
    "    for i in range(0, len(wordList) - 2, 3):\n",
    "        trigram = wordList[i] + \" \" + wordList[i + 1] + \" \" + wordList[i+2]\n",
    "        if trigram in outDict:\n",
    "            outDict[trigram] = outDict[trigram] + 1\n",
    "        else:\n",
    "            outDict[trigram] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToTxt(text, path, fileName, mode):\n",
    "    fout = open(path + \"/\" + fileName, mode)\n",
    "    print(\"Writing to file  \" + fileName + \" at \" + path)\n",
    "    fout.write(text)\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_count(wordList,outDict):\n",
    "    for word in wordList:\n",
    "        if word in outDict:\n",
    "            outDict[word] = outDict[word] + 1\n",
    "        else:\n",
    "            outDict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_list(path, fileName):\n",
    "    fp = open(path + \"/\" + fileName, \"r+\")\n",
    "    print(\"Getting word count....\" + fileName)\n",
    "    text = fp.read()\n",
    "    text = text.replace(\"\\n\\n\", \" </s> <s> \")\n",
    "    text = text.replace(\".\",\" . \")\n",
    "    text = text.replace(\",\",\" , \")\n",
    "    text = text.replace(\"?\",\" ? \")\n",
    "    text = text.strip().strip()\n",
    "    text = \" \".join(text.split()).lower()\n",
    "    wordList = text.split()\n",
    "    return wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_train(wordList):\n",
    "    processed_text = \"\"\n",
    "    for word in wordList:\n",
    "        if word_count[word] <= 3:\n",
    "            processed_text = processed_text + \"UNK \"\n",
    "        else:\n",
    "            processed_text = processed_text + word + \" \"\n",
    "    writeToTxt(processed_text, outPathText, file, \"w+\")\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_test(wordList):\n",
    "    processed_text = \"\"\n",
    "    for word in wordList:\n",
    "        if word not in unigram_count:\n",
    "            processed_text = processed_text + \"UNK \"\n",
    "        elif unigram_count[word] <= 3:\n",
    "            processed_text = processed_text + \"UNK \"\n",
    "        else:\n",
    "            processed_text = processed_text + word + \" \"\n",
    "#     writeToTxt(processed_text,outPathText,\"heldOut_\"+ file, \"w+\")\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngram_json2txt():\n",
    "    for file in os.listdir(outPathJson):\n",
    "        if file.endswith(\"json\"):\n",
    "            with open(\"./Output/\" + file) as json_f:\n",
    "                print(\"Reading file... \" + file)\n",
    "                data = json.load(json_f)\n",
    "                nGrams = \"\"\n",
    "                for k, v in sorted(data.items(), key=lambda item: item[1], reverse=True):\n",
    "                    nGrams = nGrams + k + \" : \" + str(v) + \"\\n\"\n",
    "                writeToTxt(nGrams, outPathJson, file.replace(\"_c\",\"C\").replace(\"json\",\"txt\"), \"w+\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngram_txt(data,name):\n",
    "    nGrams = \"\"\n",
    "    for k, v in sorted(data.items(), key=lambda item: item[1], reverse=True):\n",
    "        nGrams = nGrams + k + \" : \" + str(v) + \"\\n\"\n",
    "    writeToTxt(nGrams, outPathJson,name + \".txt\" , \"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity(test_text,N,lambdas):\n",
    "    l1 = lambdas[0]\n",
    "    l2 = lambdas[1]\n",
    "    l3 = lambdas[2]\n",
    "    test_text = test_text.strip()\n",
    "    wordList = test_text.split(\" \")\n",
    "    wordList = filter(lambda x: len(x) != 0, wordList) \n",
    "    totalWords = 0\n",
    "    log_trigram_prob = 0\n",
    "    for i in range(0,len(wordList)-3):\n",
    "        trigram_prob = 0\n",
    "        bigram_prob = 0\n",
    "        unigram_prob = 0\n",
    "        n0 = wordList[i]\n",
    "        n1 = wordList[i+1]\n",
    "        n2 = wordList[i+2]\n",
    "#         if n2 not in unigram_count:\n",
    "#             print(wordList[i-1] + \"|\"+n0 +\"|\"+ n1 +\"|\"+n2+\"|\" + wordList[i+3] +\"|\" + wordList[i+4] + \" \" + wordList[i+5])\n",
    "#             return -1;\n",
    "        unigram_prob = float(unigram_count[n2])/N\n",
    "        if n1 + \" \" + n2 in bigram_count:\n",
    "            bigram_prob = float(bigram_count[n1+ \" \" + n2]) / unigram_count[n1]\n",
    "        else :\n",
    "            bigram_prob = 0\n",
    "        if n0 + \" \" + n1 + \" \" + n2 in trigram_count and n0 + \" \" + n1 in bigram_count:\n",
    "            trigram_prob = float(trigram_count[n0 + \" \" + n1 + \" \" + n2]) / bigram_count[n0 + \" \" + n1]\n",
    "        else:\n",
    "            trigram_prob = 0\n",
    "#         print(\"|\"+n0 +\"|\"+ n1 +\"|\"+n2+\"|\"+ str(l1*unigram_prob) + \" \"+ str(l2*bigram_prob) + \" \" + str(l3*trigram_prob))\n",
    "        log_trigram_prob += math.log(l1*trigram_prob + l2*bigram_prob + l3*unigram_prob,2)\n",
    "        totalWords += 1\n",
    "    log_perplexity = -1 * log_trigram_prob / totalWords\n",
    "#     print(\"log_trigram_prob \" + str(log_trigram_prob) + \" \" + str(totalWords))\n",
    "    perplexity = math.pow(2,log_perplexity)\n",
    "    print(\"lambda: \" + str(lambdas[0]) + \" \" + str(lambdas[1]) + \" \" + str(lambdas[2]) + \" \" + \"Perplexity :\" + str(perplexity))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     i = 0\n",
    "def grid_search():\n",
    "    heldOut = 1\n",
    "    fileList = os.listdir(inPath)\n",
    "    for heldOut in range(9,len(fileList)-1):\n",
    "        initialize_dicts()\n",
    "        heldOutFileList = fileList[heldOut:heldOut+2]\n",
    "        for file in fileList:\n",
    "            if file.endswith(fileExtension) and file not in heldOutFileList:\n",
    "                wordList = get_word_list(file)\n",
    "                get_word_count(wordList,word_count)\n",
    "                processed_text = process_file_train(wordList)\n",
    "                wordList_UNK = processed_text.split()\n",
    "                createUnigrams(wordList_UNK,unigram_count)\n",
    "                createBigrams(wordList_UNK,bigram_count)\n",
    "                createTrigrams(wordList_UNK,trigram_count)\n",
    "\n",
    "        print(\"========================\")\n",
    "        print(\"Testing on held out data .......\")\n",
    "        print(\"========================\")\n",
    "        test_text = \"\"\n",
    "        for f in heldOutFileList:\n",
    "            print(f)\n",
    "            if f.endswith(fileExtension):\n",
    "                wordList = get_word_list(f)\n",
    "                test_text = test_text + process_file_test(wordList)\n",
    "        minPerplexity = 0\n",
    "        for l in lambdas:\n",
    "            pp = calculate_perplexity(test_text,sum(unigram_count.values()),l)\n",
    "            if pp < minPerplexity:\n",
    "                minPerplexity = pp\n",
    "                minLambda = l\n",
    "        return l\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting word count....9.txt\n",
      "Getting word count....8.txt\n",
      "Getting word count....5.txt\n",
      "Getting word count....4.txt\n",
      "Getting word count....6.txt\n",
      "Getting word count....7.txt\n",
      "Getting word count....3.txt\n",
      "Getting word count....2.txt\n",
      "========================\n",
      "Testing on held out data .......\n",
      "========================\n",
      "0.txt\n",
      "Getting word count....0.txt\n",
      "1.txt\n",
      "Getting word count....1.txt\n",
      "lambda: 0.4 0.3 0.3 Perplexity :164.885799709\n",
      "lambda: 0.3 0.4 0.3 Perplexity :161.912968675\n",
      "lambda: 0.1 0.7 0.2 Perplexity :171.350439678\n",
      "lambda: 0.5 0.4 0.3 Perplexity :137.521071543\n",
      "lambda: 0.1 0.4 0.5 Perplexity :176.646946205\n",
      "lambda: 0.7 0.2 0.1 Perplexity :203.917143415\n",
      "lambda: 0.8 0.1 0.1 Perplexity :235.985725038\n",
      "lambda: 0.1 0.8 0.1 Perplexity :182.277314697\n",
      "lambda: 0.1 0.2 0.8 Perplexity :187.304344044\n"
     ]
    }
   ],
   "source": [
    "maxLam = grid_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLM():\n",
    "    fileList = os.listdir(inPath)\n",
    "    initialize_dicts()\n",
    "    for file in fileList:\n",
    "        if file.endswith(fileExtension):\n",
    "            wordList = get_word_list(inPath,file)\n",
    "            get_word_count(wordList,word_count)\n",
    "            processed_text = process_file_train(wordList)\n",
    "            wordList_UNK = processed_text.split()\n",
    "            createUnigrams(wordList_UNK,unigram_count)\n",
    "            createBigrams(wordList_UNK,bigram_count)\n",
    "            createTrigrams(wordList_UNK,trigram_count)\n",
    "\n",
    "    generate_ngram_txt(unigram_count,\"unigram\")\n",
    "    generate_ngram_txt(bigram_count,\"bigram\")\n",
    "    generate_ngram_txt(trigram_count,\"trigram\")\n",
    "\n",
    "    print(\"Testing.......\")\n",
    "    print(\"========================\")\n",
    "    for f in os.listdir(testPath):\n",
    "        test_text = \"\"\n",
    "        if f.endswith(fileExtension):\n",
    "            wordList = get_word_list(f)\n",
    "            test_text = process_file_test(wordList)\n",
    "        pp = calculate_perplexity(test_text,sum(unigram_count.values()),minLambda)\n",
    "        print(\"File : \" + f + \" Perplexity: \" + pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting word count....9.txt\n",
      "Getting word count....8.txt\n",
      "Getting word count....5.txt\n",
      "Getting word count....4.txt\n",
      "Getting word count....6.txt\n",
      "Getting word count....7.txt\n",
      "Getting word count....3.txt\n",
      "Getting word count....2.txt\n",
      "Getting word count....0.txt\n",
      "Getting word count....1.txt\n",
      "Writing to file  unigram.txt at ./Output\n",
      "Writing to file  bigram.txt at ./Output\n",
      "Writing to file  trigram.txt at ./Output\n",
      "Testing.......\n",
      "========================\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './train/test01.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-474-d5c260f3023c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-472-3bb40a079141>\u001b[0m in \u001b[0;36mtrainLM\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtest_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileExtension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mwordList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mtest_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_file_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munigram_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminLambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-403-96fc30547ae2>\u001b[0m in \u001b[0;36mget_word_list\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_word_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minPath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Getting word count....\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" </s> <s> \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: './train/test01.txt'"
     ]
    }
   ],
   "source": [
    "trainLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing.......\n",
      "========================\n",
      "Getting word count....test01.txt\n",
      "lambda: 0.5 0.4 0.3 Perplexity :318.590021846\n",
      "File : test01.txt Perplexity: 318.590021846\n",
      "Getting word count....test02.txt\n",
      "lambda: 0.5 0.4 0.3 Perplexity :172.305120944\n",
      "File : test02.txt Perplexity: 172.305120944\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing.......\")\n",
    "print(\"========================\")\n",
    "for f in os.listdir(testPath):\n",
    "    test_text = \"\"\n",
    "    if f.endswith(fileExtension):\n",
    "        wordList = get_word_list(testPath,f)\n",
    "        test_text = process_file_test(wordList)\n",
    "    pp = calculate_perplexity(test_text,sum(unigram_count.values()),minLambda)\n",
    "    print(\"File : \" + f + \" Perplexity: \" + str(pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
